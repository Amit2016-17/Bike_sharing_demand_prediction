{"cells":[{"cell_type":"code","source":["#Read dataset in Spark\ndf = sqlContext.read.load(\"dbfs:/databricks-datasets/bikeSharing/data-001/day.csv\", \n                          format='com.databricks.spark.csv', \n                          header='true', \n                          inferSchema='true')\n#This is databrick dataset of bike sharing, have done project with given dataset though"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":1},{"cell_type":"code","source":["#2. Get summary of data and variable types\ndf.printSchema()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- instant: integer (nullable = true)\n-- dteday: timestamp (nullable = true)\n-- season: integer (nullable = true)\n-- yr: integer (nullable = true)\n-- mnth: integer (nullable = true)\n-- holiday: integer (nullable = true)\n-- weekday: integer (nullable = true)\n-- workingday: integer (nullable = true)\n-- weathersit: integer (nullable = true)\n-- temp: double (nullable = true)\n-- atemp: double (nullable = true)\n-- hum: double (nullable = true)\n-- windspeed: double (nullable = true)\n-- casual: integer (nullable = true)\n-- registered: integer (nullable = true)\n-- cnt: integer (nullable = true)\n\n</div>"]}}],"execution_count":2},{"cell_type":"code","source":["#df.show(5)\ndisplay(df.take(5))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>instant</th><th>dteday</th><th>season</th><th>yr</th><th>mnth</th><th>holiday</th><th>weekday</th><th>workingday</th><th>weathersit</th><th>temp</th><th>atemp</th><th>hum</th><th>windspeed</th><th>casual</th><th>registered</th><th>cnt</th></tr></thead><tbody><tr><td>1</td><td>2011-01-01T00:00:00.000+0000</td><td>1</td><td>0</td><td>1</td><td>0</td><td>6</td><td>0</td><td>2</td><td>0.344167</td><td>0.363625</td><td>0.805833</td><td>0.160446</td><td>331</td><td>654</td><td>985</td></tr><tr><td>2</td><td>2011-01-02T00:00:00.000+0000</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>2</td><td>0.363478</td><td>0.353739</td><td>0.696087</td><td>0.248539</td><td>131</td><td>670</td><td>801</td></tr><tr><td>3</td><td>2011-01-03T00:00:00.000+0000</td><td>1</td><td>0</td><td>1</td><td>0</td><td>1</td><td>1</td><td>1</td><td>0.196364</td><td>0.189405</td><td>0.437273</td><td>0.248309</td><td>120</td><td>1229</td><td>1349</td></tr><tr><td>4</td><td>2011-01-04T00:00:00.000+0000</td><td>1</td><td>0</td><td>1</td><td>0</td><td>2</td><td>1</td><td>1</td><td>0.2</td><td>0.212122</td><td>0.590435</td><td>0.160296</td><td>108</td><td>1454</td><td>1562</td></tr><tr><td>5</td><td>2011-01-05T00:00:00.000+0000</td><td>1</td><td>0</td><td>1</td><td>0</td><td>3</td><td>1</td><td>1</td><td>0.226957</td><td>0.22927</td><td>0.436957</td><td>0.1869</td><td>82</td><td>1518</td><td>1600</td></tr></tbody></table></div>"]}}],"execution_count":3},{"cell_type":"code","source":["#Given Train file from which data frame is generated \nbs_df = spark.sql(\"select * from bike_sharing_train_csv\")\ndisplay(bs_df.take(5))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>datetime</th><th>season</th><th>holiday</th><th>workingday</th><th>weather</th><th>temp</th><th>atemp</th><th>humidity</th><th>windspeed</th><th>casual</th><th>registered</th><th>count</th></tr></thead><tbody><tr><td>01-01-2011 00:00</td><td>1</td><td>0</td><td>0</td><td>1</td><td>9.84</td><td>14.395</td><td>81</td><td>0.0</td><td>3</td><td>13</td><td>16</td></tr><tr><td>01-01-2011 01:00</td><td>1</td><td>0</td><td>0</td><td>1</td><td>9.02</td><td>13.635</td><td>80</td><td>0.0</td><td>8</td><td>32</td><td>40</td></tr><tr><td>01-01-2011 02:00</td><td>1</td><td>0</td><td>0</td><td>1</td><td>9.02</td><td>13.635</td><td>80</td><td>0.0</td><td>5</td><td>27</td><td>32</td></tr><tr><td>01-01-2011 03:00</td><td>1</td><td>0</td><td>0</td><td>1</td><td>9.84</td><td>14.395</td><td>75</td><td>0.0</td><td>3</td><td>10</td><td>13</td></tr><tr><td>01-01-2011 04:00</td><td>1</td><td>0</td><td>0</td><td>1</td><td>9.84</td><td>14.395</td><td>75</td><td>0.0</td><td>0</td><td>1</td><td>1</td></tr></tbody></table></div>"]}}],"execution_count":4},{"cell_type":"code","source":["bs_df.printSchema()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- datetime: string (nullable = true)\n-- season: integer (nullable = true)\n-- holiday: integer (nullable = true)\n-- workingday: integer (nullable = true)\n-- weather: integer (nullable = true)\n-- temp: double (nullable = true)\n-- atemp: double (nullable = true)\n-- humidity: integer (nullable = true)\n-- windspeed: double (nullable = true)\n-- casual: integer (nullable = true)\n-- registered: integer (nullable = true)\n-- count: integer (nullable = true)\n\n</div>"]}}],"execution_count":5},{"cell_type":"code","source":["bs_df.describe().show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------+----------------+------------------+-------------------+------------------+------------------+------------------+-----------------+------------------+------------------+-----------------+------------------+------------------+\nsummary|        datetime|            season|            holiday|        workingday|           weather|              temp|            atemp|          humidity|         windspeed|           casual|        registered|             count|\n+-------+----------------+------------------+-------------------+------------------+------------------+------------------+-----------------+------------------+------------------+-----------------+------------------+------------------+\n  count|           10886|             10886|              10886|             10886|             10886|             10886|            10886|             10886|             10886|            10886|             10886|             10886|\n   mean|            null|2.5066139996325556|0.02856880396839978|0.6808745177291935| 1.418427337865148|20.230859819952173|23.65508405291192| 61.88645967297446|12.799395406945093|36.02195480433584| 155.5521771082124|191.57413191254824|\n stddev|            null|1.1161743093443237|0.16659885062470944|0.4661591687997361|0.6338385858190968| 7.791589843987573| 8.47460062648494|19.245033277394704|  8.16453732683871|49.96047657264955|151.03903308192452|181.14445383028493|\n    min|01-01-2011 00:00|                 1|                  0|                 0|                 1|              0.82|             0.76|                 0|               0.0|                0|                 0|                 1|\n    max|19-12-2012 23:00|                 4|                  1|                 1|                 4|              41.0|           45.455|               100|           56.9969|              367|               886|               977|\n+-------+----------------+------------------+-------------------+------------------+------------------+------------------+-----------------+------------------+------------------+-----------------+------------------+------------------+\n\n</div>"]}}],"execution_count":6},{"cell_type":"code","source":["bs_df.explain()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">== Physical Plan ==\n*(1) FileScan csv default.bike_sharing_train_csv[datetime#254,season#255,holiday#256,workingday#257,weather#258,temp#259,atemp#260,humidity#261,windspeed#262,casual#263,registered#264,count#265] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex[dbfs:/FileStore/tables/train.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct&lt;datetime:string,season:int,holiday:int,workingday:int,weather:int,temp:double,atemp:double...\n</div>"]}}],"execution_count":7},{"cell_type":"code","source":["#Check for any missing value in dataset and treat it\nprint(bs_df.count())\ndf_no_null = bs_df.na.drop()\nprint(df_no_null.count())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">10886\n10886\n</div>"]}}],"execution_count":8},{"cell_type":"code","source":["#Check what are the distinct seasons present to explode them\ndisplay(bs_df.select('season').distinct())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>season</th></tr></thead><tbody><tr><td>1</td></tr><tr><td>3</td></tr><tr><td>4</td></tr><tr><td>2</td></tr></tbody></table></div>"]}}],"execution_count":9},{"cell_type":"code","source":["#user defined function to help creat new columns\ndef valueToCategory(value, encoding_index):\n   if(value == encoding_index):\n      return 1\n   else:\n    return 0"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":10},{"cell_type":"code","source":["#Explode season column into separate columns such as season_<val> and drop season\nfrom pyspark.sql.functions import udf\nfrom pyspark.sql.functions import lit\nfrom pyspark.sql.types import *\nfrom pyspark.sql.functions import col\nudfValueToCategory = udf(valueToCategory, IntegerType())\nbs_df_encoded = (bs_df.withColumn(\"season_1\", udfValueToCategory(col('season'),lit(1)))\n                     .withColumn(\"season_2\", udfValueToCategory(col('season'),lit(2)))\n                     .withColumn(\"season_3\", udfValueToCategory(col('season'),lit(3)))\n                     .withColumn(\"season_4\", udfValueToCategory(col('season'),lit(4))))\nbs_df_encoded = bs_df_encoded.drop('season')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":11},{"cell_type":"code","source":["display(bs_df_encoded.take(5))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>datetime</th><th>holiday</th><th>workingday</th><th>weather</th><th>temp</th><th>atemp</th><th>humidity</th><th>windspeed</th><th>casual</th><th>registered</th><th>count</th><th>season_1</th><th>season_2</th><th>season_3</th><th>season_4</th></tr></thead><tbody><tr><td>01-01-2011 00:00</td><td>0</td><td>0</td><td>1</td><td>9.84</td><td>14.395</td><td>81</td><td>0.0</td><td>3</td><td>13</td><td>16</td><td>1</td><td>0</td><td>0</td><td>0</td></tr><tr><td>01-01-2011 01:00</td><td>0</td><td>0</td><td>1</td><td>9.02</td><td>13.635</td><td>80</td><td>0.0</td><td>8</td><td>32</td><td>40</td><td>1</td><td>0</td><td>0</td><td>0</td></tr><tr><td>01-01-2011 02:00</td><td>0</td><td>0</td><td>1</td><td>9.02</td><td>13.635</td><td>80</td><td>0.0</td><td>5</td><td>27</td><td>32</td><td>1</td><td>0</td><td>0</td><td>0</td></tr><tr><td>01-01-2011 03:00</td><td>0</td><td>0</td><td>1</td><td>9.84</td><td>14.395</td><td>75</td><td>0.0</td><td>3</td><td>10</td><td>13</td><td>1</td><td>0</td><td>0</td><td>0</td></tr><tr><td>01-01-2011 04:00</td><td>0</td><td>0</td><td>1</td><td>9.84</td><td>14.395</td><td>75</td><td>0.0</td><td>0</td><td>1</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td></tr></tbody></table></div>"]}}],"execution_count":12},{"cell_type":"code","source":["#Execute the same for weather as weather_<val> and drop weather\ndisplay(bs_df.select('weather').distinct())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>weather</th></tr></thead><tbody><tr><td>1</td></tr><tr><td>3</td></tr><tr><td>4</td></tr><tr><td>2</td></tr></tbody></table></div>"]}}],"execution_count":13},{"cell_type":"code","source":["bs_df_encoded = (bs_df_encoded.withColumn(\"weather_1\", udfValueToCategory(col('weather'),lit(1)))\n                     .withColumn(\"weather_2\", udfValueToCategory(col('weather'),lit(2)))\n                     .withColumn(\"weather_3\", udfValueToCategory(col('weather'),lit(3)))\n                     .withColumn(\"weather_4\", udfValueToCategory(col('weather'),lit(4))))\nbs_df_encoded = bs_df_encoded.drop('weather')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":14},{"cell_type":"code","source":["display(bs_df_encoded.take(5))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>datetime</th><th>holiday</th><th>workingday</th><th>temp</th><th>atemp</th><th>humidity</th><th>windspeed</th><th>casual</th><th>registered</th><th>count</th><th>season_1</th><th>season_2</th><th>season_3</th><th>season_4</th><th>weather_1</th><th>weather_2</th><th>weather_3</th><th>weather_4</th></tr></thead><tbody><tr><td>01-01-2011 00:00</td><td>0</td><td>0</td><td>9.84</td><td>14.395</td><td>81</td><td>0.0</td><td>3</td><td>13</td><td>16</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td></tr><tr><td>01-01-2011 01:00</td><td>0</td><td>0</td><td>9.02</td><td>13.635</td><td>80</td><td>0.0</td><td>8</td><td>32</td><td>40</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td></tr><tr><td>01-01-2011 02:00</td><td>0</td><td>0</td><td>9.02</td><td>13.635</td><td>80</td><td>0.0</td><td>5</td><td>27</td><td>32</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td></tr><tr><td>01-01-2011 03:00</td><td>0</td><td>0</td><td>9.84</td><td>14.395</td><td>75</td><td>0.0</td><td>3</td><td>10</td><td>13</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td></tr><tr><td>01-01-2011 04:00</td><td>0</td><td>0</td><td>9.84</td><td>14.395</td><td>75</td><td>0.0</td><td>0</td><td>1</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td></tr></tbody></table></div>"]}}],"execution_count":15},{"cell_type":"code","source":["# Split datetime into meaningful columns such as hour,day,month,year,etc\nfrom pyspark.sql.functions import split\nfrom pyspark.sql.functions import *\nfrom pyspark.sql.types import *\nbs_df_encoded = bs_df_encoded.withColumn('hour',  split(split(bs_df_encoded['datetime'], ' ')[1], ':')[0].cast('int'))\nbs_df_encoded = bs_df_encoded.withColumn('month', split(split(bs_df_encoded['datetime'], ' ')[0], '-')[0].cast('int'))\nbs_df_encoded = bs_df_encoded.withColumn('day', split(split(bs_df_encoded['datetime'], ' ')[0], '-')[1].cast('int'))\nbs_df_encoded = bs_df_encoded.withColumn('year', split(split(bs_df_encoded['datetime'], ' ')[0], '-')[2].cast('int'))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":16},{"cell_type":"code","source":["display(bs_df_encoded.take(5))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>datetime</th><th>holiday</th><th>workingday</th><th>temp</th><th>atemp</th><th>humidity</th><th>windspeed</th><th>casual</th><th>registered</th><th>count</th><th>season_1</th><th>season_2</th><th>season_3</th><th>season_4</th><th>weather_1</th><th>weather_2</th><th>weather_3</th><th>weather_4</th><th>hour</th><th>month</th><th>day</th><th>year</th></tr></thead><tbody><tr><td>01-01-2011 00:00</td><td>0</td><td>0</td><td>9.84</td><td>14.395</td><td>81</td><td>0.0</td><td>3</td><td>13</td><td>16</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td><td>2011</td></tr><tr><td>01-01-2011 01:00</td><td>0</td><td>0</td><td>9.02</td><td>13.635</td><td>80</td><td>0.0</td><td>8</td><td>32</td><td>40</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td><td>1</td><td>2011</td></tr><tr><td>01-01-2011 02:00</td><td>0</td><td>0</td><td>9.02</td><td>13.635</td><td>80</td><td>0.0</td><td>5</td><td>27</td><td>32</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>2</td><td>1</td><td>1</td><td>2011</td></tr><tr><td>01-01-2011 03:00</td><td>0</td><td>0</td><td>9.84</td><td>14.395</td><td>75</td><td>0.0</td><td>3</td><td>10</td><td>13</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>3</td><td>1</td><td>1</td><td>2011</td></tr><tr><td>01-01-2011 04:00</td><td>0</td><td>0</td><td>9.84</td><td>14.395</td><td>75</td><td>0.0</td><td>0</td><td>1</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>4</td><td>1</td><td>1</td><td>2011</td></tr></tbody></table></div>"]}}],"execution_count":17},{"cell_type":"code","source":["\nbs_df_encoded.printSchema()\nbs_df_encoded = bs_df_encoded.drop('datetime')\nbs_df_encoded = bs_df_encoded.withColumnRenamed(\"count\", \"label\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- datetime: string (nullable = true)\n-- holiday: integer (nullable = true)\n-- workingday: integer (nullable = true)\n-- temp: double (nullable = true)\n-- atemp: double (nullable = true)\n-- humidity: integer (nullable = true)\n-- windspeed: double (nullable = true)\n-- casual: integer (nullable = true)\n-- registered: integer (nullable = true)\n-- count: integer (nullable = true)\n-- season_1: integer (nullable = true)\n-- season_2: integer (nullable = true)\n-- season_3: integer (nullable = true)\n-- season_4: integer (nullable = true)\n-- weather_1: integer (nullable = true)\n-- weather_2: integer (nullable = true)\n-- weather_3: integer (nullable = true)\n-- weather_4: integer (nullable = true)\n-- hour: integer (nullable = true)\n-- month: integer (nullable = true)\n-- day: integer (nullable = true)\n-- year: integer (nullable = true)\n\n</div>"]}}],"execution_count":18},{"cell_type":"code","source":["#Split the dataset into train and train_test\nfrom pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\ntrain, test = bs_df_encoded.randomSplit([0.9, 0.1], seed=12345)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":19},{"cell_type":"code","source":["#The features are assembled to send it to model\nfrom pyspark.ml.linalg import Vectors\nfrom pyspark.ml.feature import VectorAssembler\n\nassembler = VectorAssembler(\n    inputCols=[\"holiday\",\"workingday\",\"temp\",\"atemp\",\"humidity\",\"windspeed\",\"casual\",\"registered\",\"label\",\"season_1\",\"season_2\",\"season_3\",\"season_4\",\"weather_1\",\"weather_2\",\"weather_3\",\"weather_4\", \"hour\", \"month\", \"day\", \"year\"],\n    outputCol=\"features\")\n\noutput = assembler.transform(train)\nprint(\"Assembled columns 'hour', 'day' etc  to vector column 'features'\")\ndisplay(output.take(5))\nprint(output.count())\ntrain_output = output.na.drop()\nprint(train_output.count())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>holiday</th><th>workingday</th><th>temp</th><th>atemp</th><th>humidity</th><th>windspeed</th><th>casual</th><th>registered</th><th>label</th><th>season_1</th><th>season_2</th><th>season_3</th><th>season_4</th><th>weather_1</th><th>weather_2</th><th>weather_3</th><th>weather_4</th><th>hour</th><th>month</th><th>day</th><th>year</th><th>features</th></tr></thead><tbody><tr><td>0</td><td>0</td><td>3.28</td><td>2.275</td><td>79</td><td>31.0009</td><td>0</td><td>24</td><td>24</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>1</td><td>12</td><td>2</td><td>2012</td><td>List(0, 21, List(2, 3, 4, 5, 7, 8, 9, 15, 17, 18, 19, 20), List(3.28, 2.275, 79.0, 31.0009, 24.0, 24.0, 1.0, 1.0, 1.0, 12.0, 2.0, 2012.0))</td></tr><tr><td>0</td><td>0</td><td>3.28</td><td>3.79</td><td>53</td><td>16.9979</td><td>0</td><td>26</td><td>26</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>8</td><td>12</td><td>2</td><td>2012</td><td>List(0, 21, List(2, 3, 4, 5, 7, 8, 9, 13, 17, 18, 19, 20), List(3.28, 3.79, 53.0, 16.9979, 26.0, 26.0, 1.0, 1.0, 8.0, 12.0, 2.0, 2012.0))</td></tr><tr><td>0</td><td>0</td><td>3.28</td><td>4.545</td><td>53</td><td>12.998</td><td>0</td><td>1</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>4</td><td>9</td><td>1</td><td>2011</td><td>List(0, 21, List(2, 3, 4, 5, 7, 8, 9, 13, 17, 18, 19, 20), List(3.28, 4.545, 53.0, 12.998, 1.0, 1.0, 1.0, 1.0, 4.0, 9.0, 1.0, 2011.0))</td></tr><tr><td>0</td><td>0</td><td>3.28</td><td>4.545</td><td>53</td><td>12.998</td><td>0</td><td>1</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>5</td><td>9</td><td>1</td><td>2011</td><td>List(0, 21, List(2, 3, 4, 5, 7, 8, 9, 13, 17, 18, 19, 20), List(3.28, 4.545, 53.0, 12.998, 1.0, 1.0, 1.0, 1.0, 5.0, 9.0, 1.0, 2011.0))</td></tr><tr><td>0</td><td>0</td><td>3.28</td><td>4.545</td><td>53</td><td>12.998</td><td>1</td><td>5</td><td>6</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>7</td><td>9</td><td>1</td><td>2011</td><td>List(1, 21, List(), List(0.0, 0.0, 3.28, 4.545, 53.0, 12.998, 1.0, 5.0, 6.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 7.0, 9.0, 1.0, 2011.0))</td></tr></tbody></table></div>"]}}],"execution_count":20},{"cell_type":"code","source":["test_output = assembler.transform(test)\nprint(test_output.count())\ntrain_output = test_output.na.drop()\nprint(test_output.count())\nprint(\"Assembled columns 'hour', 'day' etc  to vector column 'features'\")\n#.select(\"features\", \"clicked\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">1089\n1089\nAssembled columns &apos;hour&apos;, &apos;day&apos; etc  to vector column &apos;features&apos;\n</div>"]}}],"execution_count":21},{"cell_type":"code","source":["from pyspark.ml.evaluation import RegressionEvaluator\nfrom pyspark.ml.regression import LinearRegression\nlr = LinearRegression(maxIter=10)\n\n# Fit the model\nlrModel = lr.fit(train_output)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":22},{"cell_type":"code","source":["# Print the coefficients and intercept for logistic regression\nprint(\"Coefficients: \" + str(lrModel.coefficients))\nprint(\"Intercept: \" + str(lrModel.intercept))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Coefficients: [0.241007000329,0.0240300559307,-0.00329772606512,-0.0038201221511,-0.00311898556861,0.00062578456448,0.563257347413,0.563189130437,0.436769734736,0.647037334628,0.239546459467,-0.170680495115,-0.686157844747,-0.0505300374949,0.0248775702221,0.0845720083375,0.0,0.00476996706435,0.00572325553762,0.158668761597,-0.0867775035524]\nIntercept: 173.7435412550812\n</div>"]}}],"execution_count":23},{"cell_type":"code","source":["import pyspark.sql.functions\npredictions = lrModel.transform(test_output)\\\n    .select(\"features\", \"label\", \"prediction\")\\\n    .take(10)\ndisplay(predictions)\n\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\nfrom pyspark.mllib.evaluation import BinaryClassificationMetrics\n# testRDD = test.rdd \n# predictionAndLabels = testRDD.map(lambda lp: (float(model.predict(lp.features)), lp.label))\n# # Evaluate model\n# metrics = BinaryClassificationMetrics(predictionAndLabels)\n# f1Score = metrics.fMeasure()\n# print(f1Score)\nfrom pyspark.ml.evaluation import RegressionEvaluator\nlr_evaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"label\",metricName=\"r2\")\n# print(\"R Squared (R2) on test data = %g\" % lr_evaluator.evaluate(predictions))\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>features</th><th>label</th><th>prediction</th></tr></thead><tbody><tr><td>List(0, 21, List(2, 3, 4, 5, 7, 8, 9, 13, 17, 18, 19, 20), List(3.28, 4.545, 53.0, 12.998, 18.0, 18.0, 1.0, 1.0, 7.0, 12.0, 2.0, 2012.0))</td><td>18</td><td>17.977026052947167</td></tr><tr><td>List(0, 21, List(2, 3, 4, 5, 7, 8, 9, 13, 17, 18, 19, 20), List(4.1, 3.03, 39.0, 30.0026, 22.0, 22.0, 1.0, 1.0, 23.0, 8.0, 1.0, 2011.0))</td><td>22</td><td>22.015787070326525</td></tr><tr><td>List(0, 21, List(2, 3, 4, 5, 7, 8, 9, 13, 17, 18, 19, 20), List(5.74, 7.575, 43.0, 11.0014, 28.0, 28.0, 1.0, 1.0, 22.0, 12.0, 2.0, 2012.0))</td><td>28</td><td>28.058417248633106</td></tr><tr><td>List(1, 21, List(), List(0.0, 0.0, 6.56, 6.06, 40.0, 31.0009, 4.0, 92.0, 96.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 18.0, 12.0, 2.0, 2012.0))</td><td>96</td><td>96.06176876485841</td></tr><tr><td>List(1, 21, List(), List(0.0, 0.0, 6.56, 6.82, 40.0, 22.0028, 4.0, 44.0, 48.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 18.0, 9.0, 1.0, 2011.0))</td><td>48</td><td>47.96614804695298</td></tr><tr><td>List(1, 21, List(), List(0.0, 0.0, 6.56, 6.82, 47.0, 19.0012, 5.0, 38.0, 43.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 15.0, 1.0, 2012.0))</td><td>43</td><td>42.88936084849334</td></tr><tr><td>List(1, 21, List(), List(0.0, 0.0, 6.56, 6.82, 48.0, 26.0027, 1.0, 24.0, 25.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 15.0, 1.0, 2012.0))</td><td>25</td><td>24.89586081959351</td></tr><tr><td>List(1, 21, List(), List(0.0, 0.0, 6.56, 9.85, 59.0, 6.0032, 2.0, 18.0, 20.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 15.0, 1.0, 2011.0))</td><td>20</td><td>19.91497309035597</td></tr><tr><td>List(0, 21, List(2, 3, 4, 5, 6, 7, 8, 9, 13, 18, 19, 20), List(6.56, 9.85, 69.0, 6.0032, 3.0, 27.0, 30.0, 1.0, 1.0, 12.0, 2.0, 2011.0))</td><td>30</td><td>29.944761523582343</td></tr><tr><td>List(0, 21, List(2, 3, 4, 7, 8, 9, 13, 17, 18, 19, 20), List(6.56, 11.365, 59.0, 1.0, 1.0, 1.0, 1.0, 5.0, 15.0, 1.0, 2011.0))</td><td>1</td><td>0.8497462836939462</td></tr></tbody></table></div>"]}}],"execution_count":24},{"cell_type":"code","source":["# Parameter grid search for best parameters to give good predictions\nfrom pyspark.ml.evaluation import RegressionEvaluator\nfrom pyspark.ml.regression import LinearRegression\nfrom pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n# We use a ParamGridBuilder to construct a grid of parameters to search over.\n# TrainValidationSplit will try all combinations of values and determine best model using\n# the evaluator.\nparamGrid = ParamGridBuilder()\\\n    .addGrid(lr.regParam, [0.1, 0.01]) \\\n    .addGrid(lr.fitIntercept, [False, True])\\\n    .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\\\n    .build()\n\n# In this case the estimator is simply the linear regression.\n# A TrainValidationSplit requires an Estimator, a set of Estimator ParamMaps, and an Evaluator.\ntvs = TrainValidationSplit(estimator=lr,\n                           estimatorParamMaps=paramGrid,\n                           evaluator=RegressionEvaluator(),\n                           # 80% of the data will be used for training, 20% for validation.\n                           trainRatio=0.8)\n\n# Run TrainValidationSplit, and choose the best set of parameters.\nmodel = tvs.fit(train_output)\n\n# Make predictions on test data. model is the model with combination of parameters\n# that performed best.\ndisplay(model.transform(test_output)\\\n    .select(\"features\", \"label\", \"prediction\")\\\n    .take(5))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>features</th><th>label</th><th>prediction</th></tr></thead><tbody><tr><td>List(0, 21, List(2, 3, 4, 5, 7, 8, 9, 13, 17, 18, 19, 20), List(3.28, 4.545, 53.0, 12.998, 18.0, 18.0, 1.0, 1.0, 7.0, 12.0, 2.0, 2012.0))</td><td>18</td><td>17.99775672379881</td></tr><tr><td>List(0, 21, List(2, 3, 4, 5, 7, 8, 9, 13, 17, 18, 19, 20), List(4.1, 3.03, 39.0, 30.0026, 22.0, 22.0, 1.0, 1.0, 23.0, 8.0, 1.0, 2011.0))</td><td>22</td><td>22.002205520528005</td></tr><tr><td>List(0, 21, List(2, 3, 4, 5, 7, 8, 9, 13, 17, 18, 19, 20), List(5.74, 7.575, 43.0, 11.0014, 28.0, 28.0, 1.0, 1.0, 22.0, 12.0, 2.0, 2012.0))</td><td>28</td><td>28.002288892258296</td></tr><tr><td>List(1, 21, List(), List(0.0, 0.0, 6.56, 6.06, 40.0, 31.0009, 4.0, 92.0, 96.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 18.0, 12.0, 2.0, 2012.0))</td><td>96</td><td>95.99923333047171</td></tr><tr><td>List(1, 21, List(), List(0.0, 0.0, 6.56, 6.82, 40.0, 22.0028, 4.0, 44.0, 48.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 18.0, 9.0, 1.0, 2011.0))</td><td>48</td><td>48.00084264442458</td></tr></tbody></table></div>"]}}],"execution_count":25},{"cell_type":"code","source":["# Random Forest Classifier model\nfrom pyspark.ml.classification import RandomForestClassifier\nfrom pyspark.ml.regression import RandomForestRegressor\nfrom pyspark.ml.feature import VectorIndexer\nfrom pyspark.ml.evaluation import RegressionEvaluator\nrf = RandomForestRegressor(labelCol=\"label\", featuresCol=\"features\", numTrees=100)\n# Train model.  This also runs the indexers.\nrf_model = rf.fit(train_output)\n# rf_model.persist()\n# Make predictions.\npredictions = rf_model.transform(test_output)\n\n# Select example rows to display.\ndisplay(predictions.select(\"prediction\", \"label\", \"features\").take(5))\n\n# Select (prediction, true label) and compute test error\nevaluator = RegressionEvaluator(\n    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\nrmse = evaluator.evaluate(predictions)\nprint(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>prediction</th><th>label</th><th>features</th></tr></thead><tbody><tr><td>26.980856309621263</td><td>18</td><td>List(0, 21, List(2, 3, 4, 5, 7, 8, 9, 13, 17, 18, 19, 20), List(3.28, 4.545, 53.0, 12.998, 18.0, 18.0, 1.0, 1.0, 7.0, 12.0, 2.0, 2012.0))</td></tr><tr><td>33.05357800429468</td><td>22</td><td>List(0, 21, List(2, 3, 4, 5, 7, 8, 9, 13, 17, 18, 19, 20), List(4.1, 3.03, 39.0, 30.0026, 22.0, 22.0, 1.0, 1.0, 23.0, 8.0, 1.0, 2011.0))</td></tr><tr><td>36.28714272390532</td><td>28</td><td>List(0, 21, List(2, 3, 4, 5, 7, 8, 9, 13, 17, 18, 19, 20), List(5.74, 7.575, 43.0, 11.0014, 28.0, 28.0, 1.0, 1.0, 22.0, 12.0, 2.0, 2012.0))</td></tr><tr><td>90.99638717240707</td><td>96</td><td>List(1, 21, List(), List(0.0, 0.0, 6.56, 6.06, 40.0, 31.0009, 4.0, 92.0, 96.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 18.0, 12.0, 2.0, 2012.0))</td></tr><tr><td>53.02938717787259</td><td>48</td><td>List(1, 21, List(), List(0.0, 0.0, 6.56, 6.82, 40.0, 22.0028, 4.0, 44.0, 48.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 18.0, 9.0, 1.0, 2011.0))</td></tr></tbody></table></div>"]}}],"execution_count":26},{"cell_type":"code","source":["# GBT Regressor model \nfrom pyspark.ml.regression import GBTRegressor\ngbt = GBTRegressor(featuresCol=\"features\", maxIter=10)\n\ngbt_model = gbt.fit(train_output)\n# Make predictions.\npredictions = gbt_model.transform(test_output)\n\n\ngbt_model.write().overwrite().save(\"bike_sharing_gbt.model\")\n# Select example rows to display.\ndisplay(predictions.select(\"prediction\", \"label\", \"features\").take(5))\n\n# Select (prediction, true label) and compute test error\nevaluator = RegressionEvaluator(\n    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\nrmse = evaluator.evaluate(predictions)\nprint(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n#Gave root mean square error \n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>prediction</th><th>label</th><th>features</th></tr></thead><tbody><tr><td>16.889233655915504</td><td>18</td><td>List(0, 21, List(2, 3, 4, 5, 7, 8, 9, 13, 17, 18, 19, 20), List(3.28, 4.545, 53.0, 12.998, 18.0, 18.0, 1.0, 1.0, 7.0, 12.0, 2.0, 2012.0))</td></tr><tr><td>16.92511614166162</td><td>22</td><td>List(0, 21, List(2, 3, 4, 5, 7, 8, 9, 13, 17, 18, 19, 20), List(4.1, 3.03, 39.0, 30.0026, 22.0, 22.0, 1.0, 1.0, 23.0, 8.0, 1.0, 2011.0))</td></tr><tr><td>30.32523546505164</td><td>28</td><td>List(0, 21, List(2, 3, 4, 5, 7, 8, 9, 13, 17, 18, 19, 20), List(5.74, 7.575, 43.0, 11.0014, 28.0, 28.0, 1.0, 1.0, 22.0, 12.0, 2.0, 2012.0))</td></tr><tr><td>95.83936857912708</td><td>96</td><td>List(1, 21, List(), List(0.0, 0.0, 6.56, 6.06, 40.0, 31.0009, 4.0, 92.0, 96.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 18.0, 12.0, 2.0, 2012.0))</td></tr><tr><td>46.025330660611566</td><td>48</td><td>List(1, 21, List(), List(0.0, 0.0, 6.56, 6.82, 40.0, 22.0028, 4.0, 44.0, 48.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 18.0, 9.0, 1.0, 2011.0))</td></tr></tbody></table></div>"]}}],"execution_count":27}],"metadata":{"name":"Bike_sharing_project_file","notebookId":4429310484614261},"nbformat":4,"nbformat_minor":0}
